container:
  port: 8080
  securityContext: {}
  # annotations to be added to the pod template
  annotations:
    "cluster-autoscaler.kubernetes.io/safe-to-evict": "true"

autoscaling:
  minReplicaCount: 1
  maxReplicaCount: 2
  averageUtilization:
    # cpu: 80
    memory: 80

image:
  # ImagePolicy and check period for automated updates
  tagSemverRange: "^1.2.x"

service:
  port: 80
  timeout: 120s
  annotations: {}

nodeSelector: {}

# additional labels to be added to all resource
labels: {}

resources:
  requests:
    cpu: 10m
    memory: 50Mi
  limits:
    cpu: 100m
    memory: 100Mi

podSecurityContext: {}
configuration: {}

disruptionBudget:
  minAvailable:
  maxUnavailable: "50%"

# list of secrets to be mounted to app pod
secretVolumes: []
#  - secretName: mysecret
#    mountPath: /mypath

# list of secret names to be used as envFrom entries
secretEnvFrom: []

encryptedSecret:
  data:
    key1: dmFsdWUx
    key2: dmFsdWUy
  mountPath: /config/secret

serviceAccount:
  # service account email address for use with workload identity, see https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity
  workloadIdentityServiceAccount:
  # secret containing a 'key.json' of the GCP service account key to be used by this app
  secretName:
  mountPath: /config/service-account

# Pick one of the service mesh configs
istio:
  enabled: false

linkerd:
  enabled: true
  proxyConfig:
    # requests need to be set in order for the HPA to work correctly
    config.linkerd.io/proxy-log-level: error # one of: trace, debug, info, warn, error
    config.linkerd.io/proxy-cpu-limit: "0.1"
    config.linkerd.io/proxy-cpu-request: "0.01"
    config.linkerd.io/proxy-memory-limit: "100Mi"
    config.linkerd.io/proxy-memory-request: "50Mi"

monitoring:
  serviceMonitor: true
  namespace: monitoring

canary:
  enabled: false
